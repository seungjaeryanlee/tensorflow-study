{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Study Week 1: Playing with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check if we have the dataset downloaded. If you see `test` and `train`, you're good to go. If you only have `test.tar.gz` and `train.tar.gz`, go ahead and decompress those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.tar.gz', 'test.tar.gz', 'test', 'train']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is divided into 10 folders with number 0~9. Every image in folder 0 is an image of the digit 0, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '9', '6', '3', '2', '4', '0', '7', '5', '8']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/mnist/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a list of filenames for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_list = glob('data/mnist/train/*/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign the label, we need to parse the path to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_path(image_path):\n",
    "    return int(train_image_list[42].split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mnist/train/1/img_29648.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_list[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_from_path(train_image_list[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data: `input_ops.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST, there is no correlation between labels 0~9. Thus, we should use a one-hot encoding for the output. In other words, a label $i$ should be transformed into a vector of length 10 with the $i$th element having value 1 and other elements having value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_onehot(int_label, label_size=10, dtype=np.uint8):\n",
    "    onehot_label = np.zeros(label_size, dtype=dtype)\n",
    "    onehot_label[int_label] = 1\n",
    "    \n",
    "    return onehot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure `int_to_onehot()` is working;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_onehot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also reshape the input to whatever shape the model is expecting. Suppose the model expects a 3D tensor (image_height, image_width, image_channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = train_image_list[42]\n",
    "image = np.array(Image.open(path))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our MNIST dataset has 1 channel since it is grayscale, so we need to specify that by reshaping it into (28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(image):\n",
    "    # return image.reshape(image.shape[0], image.shape[1], 1)\n",
    "    return np.expand_dims(image, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_image(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data: `preprocess_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should preprocess the image. We do two steps are proprocessing:\n",
    "\n",
    "1. Normalize: Change the range of values [0, 255] to [0, 1] or [-1, 1]\n",
    "2. Data Augmentation: Change the data slightly to create \"new\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, depth=255):\n",
    "    \"\"\"\n",
    "    Normalize image from [0, depth] to [-1, 1].\n",
    "    \"\"\"\n",
    "    return (image - depth) / depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure te data was normalized properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 5], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.00392157, 0.00392157, 0.01176471, 0.02352941])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(image)[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible techniques for data augmentation depend largely on the dataset. Let's look at some images in the dataset to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f70ed717470>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = train_image_list[9001]\n",
    "image = np.array(Image.open(path))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST, these would be \"good\" methods:\n",
    "\n",
    " * Hue / Saturation change\n",
    " * Rotation\n",
    " * Crop\n",
    "\n",
    "Whereas these would be \"bad\" methods:\n",
    "\n",
    " * Flip horizontally\n",
    " * Flip vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "TODO Implement data augmentation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data: `data_loader.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to be used for training. The only thing left is to load it to the model! There are multiple methods to load the data. We will use **tf.data** method recommended by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_per_epoch = len(train_image_list) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_list = [int_to_onehot(get_label_from_path(path)).tolist() for path in train_image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/mnist/train/1/img_38682.jpg', [0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_list[0], train_label_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `tf.data.Dataset` to create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_image_list, train_label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add configurations to our `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat()\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "TODO Implement data loader\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfstudy]",
   "language": "python",
   "name": "conda-env-tfstudy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
