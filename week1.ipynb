{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Study Week 1: Playing with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check if we have the dataset downloaded. If you see `test` and `train`, you're good to go. If you only have `test.tar.gz` and `train.tar.gz`, go ahead and decompress those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.tar.gz', 'test', 'train', 'train.tar.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is divided into 10 folders with number 0~9. Every image in folder 0 is an image of the digit 0, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8', '5', '2', '1', '4', '0', '9', '6', '7', '3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/mnist/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a list of filenames for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_list = glob('data/mnist/train/*/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign the label, we need to parse the path to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_path(image_path):\n",
    "    return int(train_image_list[42].split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mnist/train/8/img_21486.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_list[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_from_path(train_image_list[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape Data: `input_ops.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST, there is no correlation between labels 0~9. Thus, we should use a one-hot encoding for the output. In other words, a label $i$ should be transformed into a vector of length 10 with the $i$th element having value 1 and other elements having value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_onehot(int_label, label_size=10, dtype=np.uint8):\n",
    "    onehot_label = np.zeros(label_size, dtype=dtype)\n",
    "    onehot_label[int_label] = 1\n",
    "    \n",
    "    return onehot_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure `int_to_onehot()` is working;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_onehot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also reshape the input to whatever shape the model is expecting. Suppose the model expects a 3D tensor (image_height, image_width, image_channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = train_image_list[42]\n",
    "image = np.array(Image.open(path))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our MNIST dataset has 1 channel since it is grayscale, so we need to specify that by reshaping it into (28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(image):\n",
    "    # return image.reshape(image.shape[0], image.shape[1], 1)\n",
    "    return np.expand_dims(image, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_image(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data: `preprocess_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should preprocess the image. We do two steps are proprocessing:\n",
    "\n",
    "1. Normalize: Change the range of values [0, 255] to [0, 1] or [-1, 1]\n",
    "2. Data Augmentation: Change the data slightly to create \"new\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, depth=255):\n",
    "    \"\"\"\n",
    "    Normalize image from [0, depth] to [-1, 1].\n",
    "    \"\"\"\n",
    "    return (image - depth) / depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure te data was normalized properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(image)[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible techniques for data augmentation depend largely on the dataset. Let's look at some images in the dataset to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f72741acbe0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = train_image_list[9001]\n",
    "image = np.array(Image.open(path))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST, these would be \"good\" methods:\n",
    "\n",
    " * Hue / Saturation change\n",
    " * Rotation\n",
    " * Crop\n",
    "\n",
    "Whereas these would be \"bad\" methods:\n",
    "\n",
    " * Flip horizontally\n",
    " * Flip vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "TODO Implement data augmentation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data: `data_loader.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready to be used for training. The only thing left is to load it to the model! There are multiple methods to load the data. We will use **tf.data** method recommended by TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a list of labels like the list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_list = [int_to_onehot(get_label_from_path(path)).tolist() for path in train_image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/mnist/train/8/img_3087.jpg', [0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_list[0], train_label_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `tf.data.Dataset` to create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_image_list, train_label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add configurations to our `dataset`. We want to use minibatches for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting, we shuffle the dataset. In `dataset.shuffle()`, we need to specify a parameter called `buffer_size`. This is a shuffling method where the dataset randomly chooses from a buffer with a specified size rather than the full dataset for speed. If the size of the buffer is bigger than the size of the dataset, you get a uniformly random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make an iterator to use the `tf.data.Dataset` object we defined. We use the **one shot iterator**, the simplest iterator that does not allow changing source of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator has a `iter.get_next()` function that returns the next element. In our case, we specified a `BATCH_SIZE`, so we are given one batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([b'data/mnist/train/8/img_34197.jpg',\n",
      "       b'data/mnist/train/8/img_32513.jpg',\n",
      "       b'data/mnist/train/8/img_22575.jpg',\n",
      "       b'data/mnist/train/8/img_26740.jpg'], dtype=object), array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_loader.py`\n",
    " * [How to use dataset in TensorFlow](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfstudy]",
   "language": "python",
   "name": "conda-env-tfstudy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
